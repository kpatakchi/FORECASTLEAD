2024-09-09 21:10:45.293667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:10:45.297564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:10:45.299122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:10:45.302010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 21:10:49.285259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:10:49.287276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:10:49.288790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:10:49.290324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 21:10:53.943069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:10:53.945933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:10:53.948394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:10:53.949923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 21:10:57.482431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:10:57.485460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:10:57.488083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:10:57.490744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 21:11:00.767976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:11:00.769811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:11:00.771507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:11:00.773871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 21:11:03.748046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:11:03.751475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:11:03.754125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:11:03.756807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 21:11:06.990841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:11:06.992858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:11:06.995455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:11:06.997095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 21:11:07.972282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:11:07.974401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:11:07.975972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:11:07.977652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 21:11:28.797899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:31.812076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:32.137704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:35.115075: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7d555610 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:11:35.115141: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:35.115148: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:35.115154: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:35.115161: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:35.149007: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:11:35.445374: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-09-09 21:11:36.889203: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:37.336690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:37.913431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:38.313150: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14a5c61032d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:11:38.313215: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:38.313233: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:38.313241: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:38.313250: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:38.339599: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:11:38.346872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:38.622702: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-09-09 21:11:40.182869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:40.652937: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:41.188399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:41.691644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:43.216567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:44.447345: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14547c01d190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:11:44.447425: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:44.447439: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:44.447445: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:44.447451: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:44.479037: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:11:44.760938: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-09-09 21:11:46.673658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:47.120150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:47.674787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:47.698191: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1464538e57d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:11:47.698269: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:47.698277: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:47.698283: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:47.698289: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:47.720865: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:11:48.006727: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-09-09 21:11:48.173013: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:49.023286: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14bc00002760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:11:49.023350: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:49.023357: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:49.023363: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:49.023369: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:49.052356: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:11:49.349349: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-09-09 21:11:49.568970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:49.906029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:50.304496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:50.828116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:51.492077: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:51.899328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:11:54.362615: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1495ac1e3f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:11:54.362690: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:54.362697: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:54.362704: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:54.362710: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:54.393245: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:11:54.709813: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-09-09 21:11:55.879140: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x674d8380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:11:55.879202: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:55.879211: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:55.879217: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:55.879223: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:55.908912: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:11:56.211573: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-09-09 21:11:57.788136: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7e2de970 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:11:57.788212: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:57.788221: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:57.788227: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:57.788233: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:11:57.810999: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:11:58.098607: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
srun: Job 10299613 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=10299613.8
2024-09-09 21:29:36.195444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:29:36.197302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:29:36.199019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:29:36.201678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 21:30:18.137549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:30:18.513104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:30:23.898356: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x65fcef20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:30:23.898413: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:30:23.898420: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:30:23.898426: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:30:23.898432: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:30:23.911122: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:30:24.124342: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=10299613.9
2024-09-09 21:31:36.918658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:31:36.921539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:31:36.924180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:31:36.925911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 21:32:18.880084: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:32:19.357789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:32:19.912851: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:32:20.385838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:32:26.333857: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14d98763c270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:32:26.333923: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:32:26.333931: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:32:26.333937: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:32:26.333943: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:32:26.342385: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:32:26.536945: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=10299613.10
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
2024-09-09 21:39:37.491010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:39:37.492871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:39:37.494467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:39:37.497210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
2024-09-09 21:40:19.203831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:40:24.155163: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x142da12de810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:40:24.155218: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:40:24.155225: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:40:24.155231: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:40:24.155238: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:40:24.168209: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:40:24.361132: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=10299613.11
2024-09-09 21:57:20.494753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 21:57:20.496506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 21:57:20.499116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 21:57:20.500868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 21:58:02.587516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:58:02.940691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 21:58:08.615495: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x148de8002dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 21:58:08.615560: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:58:08.615568: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:58:08.615574: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:58:08.615580: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 21:58:08.627386: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 21:58:08.835080: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=10299613.12
2024-09-09 22:04:22.843237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 22:04:22.845106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 22:04:22.846736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 22:04:22.848311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 22:05:04.687381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:05:05.196441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:05:05.732529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:05:06.196214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:05:12.350406: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x148f7aad94a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 22:05:12.350466: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:05:12.350473: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:05:12.350479: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:05:12.350485: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:05:12.359956: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 22:05:12.577316: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=10299613.13
2024-09-09 22:11:10.523371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 22:11:10.525197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 22:11:10.526908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 22:11:10.529645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 22:11:52.354153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:11:57.597319: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1455c0012b10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 22:11:57.597378: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:11:57.597386: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:11:57.597392: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:11:57.597398: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:11:57.610050: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 22:11:57.824164: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10299613 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=10299613.14
srun: Step created for StepId=10299613.15
2024-09-09 22:21:35.365325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 22:21:35.395010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0
2024-09-09 22:21:35.368136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 22:21:35.370645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 22:21:35.372334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 22:21:35.396866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38364 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:44:00.0, compute capability: 8.0
2024-09-09 22:21:35.399282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38364 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:84:00.0, compute capability: 8.0
2024-09-09 22:21:35.402553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38364 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c4:00.0, compute capability: 8.0
2024-09-09 22:22:17.313535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:22:17.558896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:22:17.763534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:22:18.098152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:22:18.353030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:22:18.615116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:22:18.819712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:22:19.068244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2024-09-09 22:22:24.961998: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14f3a1fb3e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 22:22:24.962068: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:22:24.962076: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:22:24.962082: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:22:24.962088: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:22:24.970259: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 22:22:25.168390: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-09-09 22:22:25.435333: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x150a5c01e220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-09 22:22:25.435380: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:22:25.435388: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:22:25.435394: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:22:25.435401: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2024-09-09 22:22:25.443352: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-09 22:22:25.650034: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
