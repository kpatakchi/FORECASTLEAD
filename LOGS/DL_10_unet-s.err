mkdir: cannot create directory ‘/p/project1/deepacf’: Permission denied
mkdir: cannot create directory ‘/p/project1/deepacf’: Permission denied
2025-02-05 07:45:49.668109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14782 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:60:00.0, compute capability: 7.0
2025-02-05 07:45:49.668811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14782 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0
2025-02-05 07:45:49.669353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14782 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:88:00.0, compute capability: 7.0
2025-02-05 07:45:49.670232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14782 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0
2025-02-05 07:45:52.355764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14782 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:60:00.0, compute capability: 7.0
2025-02-05 07:45:52.356408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14782 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0
2025-02-05 07:45:52.356976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14782 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:88:00.0, compute capability: 7.0
2025-02-05 07:45:52.357530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14782 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0
2025-02-05 07:45:52.752060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14782 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:60:00.0, compute capability: 7.0
2025-02-05 07:45:52.752736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14782 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0
2025-02-05 07:45:52.753278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14782 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:88:00.0, compute capability: 7.0
2025-02-05 07:45:52.754189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14782 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0
2025-02-05 07:45:55.184658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14782 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:60:00.0, compute capability: 7.0
2025-02-05 07:45:55.185370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14782 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0
2025-02-05 07:45:55.185924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14782 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:88:00.0, compute capability: 7.0
2025-02-05 07:45:55.186464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14782 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0
2025-02-05 07:45:56.992284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14782 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:60:00.0, compute capability: 7.0
2025-02-05 07:45:56.992970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14782 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0
2025-02-05 07:45:56.993493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14782 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:88:00.0, compute capability: 7.0
2025-02-05 07:45:56.994017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14782 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0
2025-02-05 07:46:02.788544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:04.300129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:05.631186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:05.762172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:07.141126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:07.368279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:08.056095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:08.119354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:08.316495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:08.953513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:09.257586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:09.610860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:09.884099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:10.468026: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14c1cc9e67b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-02-05 07:46:10.468061: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:10.468067: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:10.468072: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:10.468093: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:10.474148: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-02-05 07:46:10.650257: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-02-05 07:46:11.370374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:12.274179: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:13.177527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 07:46:15.865842: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14ee5870b790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-02-05 07:46:15.865877: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:15.865883: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:15.865888: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:15.865910: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:15.871752: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-02-05 07:46:15.981102: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1493f0138090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-02-05 07:46:15.981138: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:15.981144: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:15.981149: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:15.981170: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:15.987046: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-02-05 07:46:16.049163: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-02-05 07:46:16.164342: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-02-05 07:46:16.465314: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x6af13170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-02-05 07:46:16.465350: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:16.465356: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:16.465361: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:16.465383: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:16.471241: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-02-05 07:46:16.649436: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-02-05 07:46:20.214325: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14fe86fed820 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-02-05 07:46:20.214360: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:20.214366: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:20.214371: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:20.214376: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 07:46:20.220422: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-02-05 07:46:20.396447: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
srun: Job 10915702 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=10915702.5
2025-02-05 08:16:47.605817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14782 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:60:00.0, compute capability: 7.0
2025-02-05 08:16:47.606448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14782 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0
2025-02-05 08:16:47.607003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14782 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:88:00.0, compute capability: 7.0
2025-02-05 08:16:47.607514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14782 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0
2025-02-05 08:17:00.394894: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:17:01.966250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:17:02.910477: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:17:03.843235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:17:10.967272: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x145d454dc5f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-02-05 08:17:10.967309: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:17:10.967315: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:17:10.967320: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:17:10.967325: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:17:10.973122: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-02-05 08:17:11.148249: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=10915702.6
2025-02-05 08:22:40.595550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14782 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:60:00.0, compute capability: 7.0
2025-02-05 08:22:40.596232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14782 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0
2025-02-05 08:22:40.596780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14782 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:88:00.0, compute capability: 7.0
2025-02-05 08:22:40.597343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14782 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0
2025-02-05 08:22:53.466151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:22:55.044267: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:22:55.976465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:22:56.922281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:23:04.124583: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14a8813f7c60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-02-05 08:23:04.124617: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:23:04.124623: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:23:04.124628: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:23:04.124633: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:23:04.130418: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-02-05 08:23:04.308313: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=10915702.7
2025-02-05 08:24:35.134215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14782 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:60:00.0, compute capability: 7.0
2025-02-05 08:24:35.134946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14782 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0
2025-02-05 08:24:35.135526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14782 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:88:00.0, compute capability: 7.0
2025-02-05 08:24:35.136109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14782 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0
2025-02-05 08:24:48.022564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:24:49.496627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:24:55.937177: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14dd1c01da20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-02-05 08:24:55.937212: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:24:55.937218: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:24:55.937223: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:24:55.937244: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:24:55.943501: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-02-05 08:24:56.122490: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 10915702 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=10915702.8
2025-02-05 08:33:47.975289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14782 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:60:00.0, compute capability: 7.0
2025-02-05 08:33:47.975969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14782 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0
2025-02-05 08:33:47.976523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14782 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:88:00.0, compute capability: 7.0
2025-02-05 08:33:47.977030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14782 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0
2025-02-05 08:34:00.798909: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:34:02.246500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:34:03.119329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:34:03.988169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600
2025-02-05 08:34:10.836306: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x6e9001e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-02-05 08:34:10.836342: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:34:10.836350: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:34:10.836355: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:34:10.836360: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0
2025-02-05 08:34:10.842014: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-02-05 08:34:11.016445: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
